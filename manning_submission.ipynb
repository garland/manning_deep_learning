{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "# A Deep Learning Domain Focused Language Model\n",
    "## Workflow for Mathew Garland  \n",
    "This Notebook must be executed as Trusted for the programmatically generated Markdown headings to display properly,\n",
    "refer: [Jupyter Issue](https://github.com/jupyter/nbconvert/issues/145). \n",
    "\n",
    "If this Notebook is not executed as Trusted some programmatically generated headings will be displayed as: __<IPython.core.display.Markdown object>__.  \n",
    "\n",
    "### Package Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# IPython is required for outputting text as Markdown\n",
    "from IPython.display import display, Markdown\n",
    "import re\n",
    "import nltk"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Download nltk word tokenizer data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to /home/matgarland/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/matgarland/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Local Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# number of csv rows to display\n",
    "DISPLAY_ROWS = 5\n",
    "# file names of csv text data\n",
    "IN_DATA_FILE = \"stackexchange_812k.csv\"\n",
    "OUT_DATA_FILE = \"Manning_Submission_1.4.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Workflow Step 1: Load the dataset into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import the csv file that holds our data\n",
    "df = pd.read_csv( IN_DATA_FILE )\n",
    "# Ensure the display of data wraps the DataFrame so all csv data in the cell is visible, i.e. no cell data truncation\n",
    "pd.set_option('max_colwidth', 0)\n",
    "pd.set_option('display.expand_frame_repr', False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Get the number of rows in the CSV data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "### The data file, stackexchange_812k.csv, consists of 812132 rows and 5 columns."
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "comment    0.681017\npost       0.206006\ntitle      0.112977\nName: category, dtype: float64"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 5
    }
   ],
   "source": [
    "# get the number of rows and columns in the original csv data\n",
    "(rows, cols) = df.shape\n",
    "# This Notebook must be executed as Trusted for Markdown headings to display properly refer: https://github.com/jupyter/nbconvert/issues/145\n",
    "display( Markdown('### The data file, {}, consists of {} rows and {} columns.'.format( IN_DATA_FILE, rows, cols )) )\n",
    "df['parent_id'].isna().sum()\n",
    "df['post_id'].isna().sum()\n",
    "df['comment_id'].isna().sum()\n",
    "df['category'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   post_id  parent_id  comment_id                                                               text category\n0  1       NaN        NaN          Eliciting priors from experts                                      title  \n1  2       NaN        NaN          What is normality?                                                 title  \n2  3       NaN        NaN          What are some valuable Statistical Analysis open source projects?  title  \n3  4       NaN        NaN          Assessing the significance of differences in distributions         title  \n4  6       NaN        NaN          The Two Cultures: statistics vs. machine learning?                 title  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>post_id</th>\n      <th>parent_id</th>\n      <th>comment_id</th>\n      <th>text</th>\n      <th>category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Eliciting priors from experts</td>\n      <td>title</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>What is normality?</td>\n      <td>title</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>What are some valuable Statistical Analysis open source projects?</td>\n      <td>title</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Assessing the significance of differences in distributions</td>\n      <td>title</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>The Two Cultures: statistics vs. machine learning?</td>\n      <td>title</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 6
    }
   ],
   "source": [
    "# display the first 5 rows of data in the csv file.\n",
    "df.head(DISPLAY_ROWS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize(t):\n",
    "    # word_tokenize() uses TreebankWordTokenizer internally\n",
    "    return ' '.join( word_tokenize(t) )\n",
    "\n",
    "def expand_contraction(t):\n",
    "    # a dictionary of english contractions mapped to the corresponding expanded form\n",
    "    # maybe not all of 'em, but certainly a good representation.\n",
    "    dict_contraction = {\n",
    "        'i\\'d'      :   'I would',\n",
    "        'i\\'ll'     :   'I will',\n",
    "        'i\\'ve'     :   'I have',\n",
    "        'i\\'m'      :   'I am',\n",
    "        'you\\'d'    :   'you would',\n",
    "        'you\\'re'   :   'you are',\n",
    "        'you\\'ll'   :   'you will',\n",
    "        'you\\'ve'   :   'you have',\n",
    "        'isn\\'t'    :   'is not',\n",
    "        'it\\'s'     :   'it is',\n",
    "        'it\\'ll'    :   'it will',\n",
    "        'it\\'d'     :   'it had',\n",
    "        'we\\'d'     :   'we would',\n",
    "        'we\\'re'    :   'we are',\n",
    "        'we\\'ll'    :   'we will',\n",
    "        'wasn\\'t'   :   'was not',\n",
    "        'weren\\'t'  :   'were not',\n",
    "        'aren\\'t'   :   'are not',\n",
    "        'they\\'d'   :   'they would',\n",
    "        'they\\'ll'  :   'they will',\n",
    "        'they\\'re'  :   'they are',\n",
    "        'they\\'ve'  :   'they have',\n",
    "        'let\\'s'    :   'let us',\n",
    "        'doesn\\'t'  :   'does not',\n",
    "        'can\\'t'    :   'can not',\n",
    "        'won\\'t'    :   'will not',\n",
    "        'wouldn\\'t' :   'would not',\n",
    "        'who\\'s'    :   'who is',\n",
    "        'what\\'s'   :   'what is',\n",
    "        'when\\'s'   :   'when is',\n",
    "        'where\\'s'  :   'where is',\n",
    "        'that\\'s'   :   'that has',\n",
    "        'that\\'d'   :   'that would',\n",
    "        'that\\'ll'  :   'that will',\n",
    "        'now\\'s'    :   'now is',\n",
    "        'how\\'s'    :   'how is',\n",
    "        'how\\'ll'   :   'how will',\n",
    "        'how\\'d'    :   'how would'\n",
    "    }\n",
    "    # a dictionary of English contractions with mapping to expanded contractions\n",
    "    # Expand all contractions in the csv text data\n",
    "    for k,v in dict_contraction.items():\n",
    "        t = re.sub( re.escape(k), v, str(t), 0, re.IGNORECASE | re.MULTILINE )\n",
    "    return ''.join(t) \n",
    " \n",
    "# (1) replace latex expressions with a space character, some have double '$' hence used regex is a modified version of \\$([^$]*)\\$.\n",
    "df['normalized']        = df['text'].replace(re.escape('\\$+([^$]+)\\$+'), ' ', regex=True )\n",
    "# (2) expand all contractions using the local function, expand_contraction()\n",
    "df['normalized']        = df['normalized'].apply(expand_contraction)\n",
    "\n",
    "# (3) Remove rows containing any of the following regex's\n",
    "# (3) Sequence: \n",
    "    # A) Remove rows containing <code> xyz blah ...</code>\n",
    "    # B) Remove rows containing <pre> xyz blah ...</pre>\n",
    "    # C) Replace \\ or \\\\ or \\\\\\ ... with blank\n",
    "# Sequence A\n",
    "#df['normalized']        = df['normalized'].replace(re.escape('<code>[^.]*</code>'), '', regex=True)\n",
    "# Sequence B\n",
    "#df['normalized']        = df['normalized'].replace(re.escape('<pre>[\\s\\S]*?<\\/pre>'), '', regex=True)\n",
    "# Sequence C\n",
    "\n",
    "# (3) Remove rows containing any of the following regex's \n",
    "    # A) Remove rows containing <code> xyz blah ...</code>\n",
    "    # B) Remove rows containing <pre> xyz blah ...</pre>\n",
    "filter =                df['normalized'].str.contains( re.escape('(<code>[^.]*<\\/code>)|(<pre>[\\s\\S]*?<\\/pre>)'), flags=re.MULTILINE | re.IGNORECASE )\n",
    "df = df[~filter]\n",
    "# (4) Replace backslashes\n",
    "df['normalized']        = df['normalized'].replace(re.escape('[\\\\]+'), '', regex=True)\n",
    "# (5) Delete any @name symbol, optionally match @name[space][comma]\n",
    "df['normalized']        = df['normalized'].replace(re.escape('@[\\s]?[aA-zZ0-9.]+[\\s:,]?'), '', regex=True)\n",
    "# (6) Remove single quotes, double quotes or back ticks\n",
    "df['normalized']        = df['normalized'].replace(re.escape('[\\'\\\"\\`]+'), '', regex=True)\n",
    "# (7) Replace occurrences of * OR ** with space.\n",
    "df['normalized']        = df['normalized'].replace(re.escape('(\\*)+'), ' ', regex=True)\n",
    "# (8) Remove any numbers optionally in parenthesis e.g 1, 1), (1,), or (1) (must trail markdown url removal)\n",
    "df['normalized']        = df['normalized'].replace(re.escape('[+\\(]?[\\d][,0-9]?[\\)]?'), '', regex=True)\n",
    "# (9) Remove text span\n",
    "df['normalized']        = df['normalized'].replace(re.escape('<span class=\"math\\.container\">[^<span]*<\\/span>'), '', regex=True)\n",
    "# (10) remove html5 node tags e.g. <p><bold>blah ...</bold><strong>blah blah ...</strong></strong></p>\n",
    "df['normalized']        = df['normalized'].replace(re.escape('(\\<(\\/)?(\\w)*(\\d)?\\>)'), '', regex=True )\n",
    "# (11) Replace >= 2 whitespace characters with a single whitespace\n",
    "df['normalized']        =df['normalized'].replace(re.escape( '[\\s]{2,}'), ' ', regex = True )\n",
    "# (12) Remove leading and trailing carriage returns and line feeds, if any\n",
    "df['normalized']        =df['normalized'].replace(re.escape( '^[\\r\\n]+|\\.|[\\r\\n]+$'), ' ', regex = True )\n",
    "# (13) tokenize string data\n",
    "df['tokenized']        = df['normalized'].apply(tokenize).str.lower()\n",
    "# Drop the normalized column\n",
    "df.drop(labels='normalized', axis=1, inplace=True)\n",
    "# display data\n",
    "df.head(DISPLAY_ROWS)\n",
    "# Save wrangled data to a local csv data file\n",
    "df.to_csv(OUT_DATA_FILE, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}